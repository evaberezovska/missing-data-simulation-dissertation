{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b233605c",
   "metadata": {},
   "source": [
    "# 3 - Classification methods on Imputed Data\n",
    "\n",
    "In this notebook we evaluate the performance of different classification methods on imputed datasets.\n",
    "\n",
    "\n",
    "## Classification Methods:\n",
    "1. **Random Forest** \n",
    "2. **Neural Network** \n",
    "3. **Support Vector Machine (SVM)** \n",
    "\n",
    "## Evaluation Metrics:\n",
    "- **F1-Score** \n",
    "- **Accuracy** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6102fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# reproducibility\n",
    "RANDOM_SEED = 57\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# create directories\n",
    "os.makedirs('results/classification', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe66be3c",
   "metadata": {},
   "source": [
    "# Functions for data pre- and post- processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885d3793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load datasets\n",
    "def load_datasets(imputation_method, prefix=\"data/imputed/iteration_1\"):\n",
    "    \"\"\"\n",
    "    Load datasets from iteration_1 folder with updated file naming\n",
    "    \"\"\"\n",
    "    # Complete datasets\n",
    "    complete_path = \"data/complete/iteration_1\"\n",
    "    train_complete = pd.read_csv(f\"{complete_path}/train_complete.csv\")\n",
    "    test_complete = pd.read_csv(f\"{complete_path}/test_complete.csv\")\n",
    "    \n",
    "    if imputation_method == \"Complete\":\n",
    "        return {\n",
    "            \"train_complete\": train_complete,\n",
    "            \"test_complete\": test_complete\n",
    "        }\n",
    "    \n",
    "    # Updated file naming based on your iteration_1 files\n",
    "    if imputation_method == \"KNN\":\n",
    "        file_suffix = \"_knn.csv\"\n",
    "    elif imputation_method == \"MICE\":\n",
    "        file_suffix = \"_mice.csv\"\n",
    "    elif imputation_method == \"Simple\":\n",
    "        file_suffix = \"_simple.csv\"\n",
    "    \n",
    "    # Load from iteration_1 folder\n",
    "    train_low = pd.read_csv(f\"{prefix}/train_low{file_suffix}\")\n",
    "    test_low = pd.read_csv(f\"{prefix}/test_low{file_suffix}\")\n",
    "    train_high = pd.read_csv(f\"{prefix}/train_high{file_suffix}\")\n",
    "    test_high = pd.read_csv(f\"{prefix}/test_high{file_suffix}\")\n",
    "    \n",
    "    return {\n",
    "        \"train_low\": train_low,\n",
    "        \"test_low\": test_low,\n",
    "        \"train_high\": train_high,\n",
    "        \"test_high\": test_high,\n",
    "        \"train_complete\": train_complete,\n",
    "        \"test_complete\": test_complete\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd300f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split data by features and target\n",
    "def prepare_data(dataset, target_column=\"target\"):\n",
    "    features = [col for col in dataset.columns if col != target_column]\n",
    "    X = dataset[features]\n",
    "    y = dataset[target_column]\n",
    "    return X, y, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43d098b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate the model\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # train \n",
    "    train_pred = model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    train_f1 = f1_score(y_train, train_pred)\n",
    "    \n",
    "    # test\n",
    "    test_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    test_f1 = f1_score(y_test, test_pred)\n",
    "    \n",
    "    return {\n",
    "        \"train_pred\": train_pred,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"train_f1\": train_f1,\n",
    "        \"test_pred\": test_pred,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"test_f1\": test_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "032db02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save predictions\n",
    "def save_predictions(actual, predicted, imputation_method, dataset_type, classifier):\n",
    "    predictions_df = pd.DataFrame({\n",
    "        \"actual\": actual,\n",
    "        \"predicted\": predicted\n",
    "    })\n",
    "    \n",
    "    filename = f\"results/classification/predictions_{dataset_type}_{imputation_method}_{classifier}.csv\"\n",
    "    predictions_df.to_csv(filename, index=False)\n",
    "    print(f\"Predictions saved to {filename}\")\n",
    "    \n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3d785fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get feature importance\n",
    "def get_feature_importance(model, classifier_type, features, X_test=None, y_test=None):\n",
    "    \n",
    "    if classifier_type == \"SVM\" and hasattr(model, \"coef_\"):\n",
    "        # SVM\n",
    "        feature_coefficients = model.coef_[0]\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature_name': features,\n",
    "            'coefficient': feature_coefficients,\n",
    "            'abs_coefficient': np.abs(feature_coefficients)\n",
    "        }).sort_values('abs_coefficient', ascending=False)\n",
    "        \n",
    "    elif classifier_type == \"RandomForest\" and hasattr(model, \"feature_importances_\"):\n",
    "        # Random Forest\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature_name': features,\n",
    "            'importance': model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "    elif classifier_type == \"NeuralNetwork\" and X_test is not None and y_test is not None:\n",
    "        # Neural Network\n",
    "        perm_importance = permutation_importance(\n",
    "            model, X_test, y_test, \n",
    "            n_repeats=10, random_state=RANDOM_SEED, scoring='accuracy'\n",
    "        )\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature_name': features,\n",
    "            'importance': perm_importance.importances_mean\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "    else:\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature_name': features,\n",
    "            'importance': np.zeros(len(features))\n",
    "        })\n",
    "        \n",
    "    return feature_importance\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdbfde0",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7419c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM fine tuning \n",
    "def train_svm_model(X_train, y_train, param_grid, cv=10, verbose=1):\n",
    "    \n",
    "      # grid search\n",
    "    svm_grid = GridSearchCV(\n",
    "        SVC(random_state=RANDOM_SEED),\n",
    "        param_grid,\n",
    "        cv=cv,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    svm_grid.fit(X_train, y_train)\n",
    "    \n",
    "    # results\n",
    "    print(f\"\\nBest parameters: {svm_grid.best_params_}\")\n",
    "    print(f\"Best cross-validation Accuracy: {svm_grid.best_score_:.4f}\")\n",
    "    \n",
    "    return svm_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6856c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest fine tuning \n",
    "def train_random_forest_model(X_train, y_train, param_grid, cv=10, verbose=1):\n",
    "\n",
    "    # grid search\n",
    "    rf_grid = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=RANDOM_SEED),\n",
    "        param_grid,\n",
    "        cv=cv,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    rf_grid.fit(X_train, y_train)\n",
    "    \n",
    "    # results\n",
    "    print(f\"\\nBest parameters: {rf_grid.best_params_}\")\n",
    "    print(f\"Best cross-validation Accuracy: {rf_grid.best_score_:.4f}\")\n",
    "    \n",
    "    return rf_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c7565628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network fine tuning \n",
    "def train_neural_network_model(X_train, y_train, param_grid, cv=5, verbose=1):\n",
    "    \n",
    "    # grid search\n",
    "    nn_grid = GridSearchCV(\n",
    "        MLPClassifier(random_state=RANDOM_SEED),\n",
    "        param_grid,\n",
    "        cv=cv,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    nn_grid.fit(X_train, y_train)\n",
    "    \n",
    "    # results\n",
    "    print(f\"\\nBest parameters: {nn_grid.best_params_}\")\n",
    "    print(f\"Best cross-validation Accuracy: {nn_grid.best_score_:.4f}\")\n",
    "    \n",
    "    return nn_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85cdc942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test model performance \n",
    "def analyze_model_performance(model_name, model, X_train, y_train, X_test, y_test, features, \n",
    "                              dataset_type, imputation_method):\n",
    "\n",
    "    # evaluate performance\n",
    "    results = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(f\"\\nTraining performance of {imputation_method} imputed {dataset_type} {model_name}:\")\n",
    "    print(f\"Accuracy: {results['train_accuracy']:.4f}, F1-Score: {results['train_f1']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nTest performance of {imputation_method} imputed {dataset_type} {model_name}:\")\n",
    "    print(f\"Accuracy: {results['test_accuracy']:.4f}, F1-Score: {results['test_f1']:.4f}\")\n",
    "\n",
    "     # get feature importance\n",
    "    if model_name == \"SVM\":\n",
    "        feature_importance = get_feature_importance(model, \"SVM\", features)\n",
    "    elif model_name == \"RandomForest\":\n",
    "        feature_importance = get_feature_importance(model, \"RandomForest\", features)\n",
    "    elif model_name == \"NeuralNetwork\":\n",
    "        feature_importance = get_feature_importance(model, \"NeuralNetwork\", features, X_test, y_test)\n",
    "    \n",
    "    print(f\"\\nFeature Importance for {dataset_type.capitalize()} Missing Data {model_name}:\")\n",
    "    print(feature_importance.head(10))  \n",
    "    \n",
    "    # save predictions\n",
    "    save_file = save_predictions(\n",
    "        y_test, results[\"test_pred\"], \n",
    "        imputation_method, dataset_type, model_name\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"feature_importance\": feature_importance,\n",
    "        \"predictions_file\": save_file\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0414d5",
   "metadata": {},
   "source": [
    "# 1. Complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f2f82fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load complete datasets\n",
    "datasets = load_datasets(\"Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ba9616",
   "metadata": {},
   "source": [
    "## 1.1 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7bd8670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "Best parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best cross-validation Accuracy: 0.9614\n"
     ]
    }
   ],
   "source": [
    "X_train_complete, y_train_complete, features = prepare_data(datasets[\"train_complete\"])\n",
    "X_test_complete, y_test_complete, _ = prepare_data(datasets[\"test_complete\"])\n",
    "\n",
    "# SVM parameters for complete dataset\n",
    "param_grid_svm_complete = {\n",
    "    'C': [10, 20, 30, 40, 50],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# train model\n",
    "svm_grid_complete = train_svm_model(X_train_complete, y_train_complete, param_grid_svm_complete, cv=5)\n",
    "best_svm_complete = svm_grid_complete.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e1a5993d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of None imputed complete SVM:\n",
      "Accuracy: 0.9843, F1-Score: 0.9846\n",
      "\n",
      "Test performance of None imputed complete SVM:\n",
      "Accuracy: 0.9767, F1-Score: 0.9773\n",
      "\n",
      "Feature Importance for Complete Missing Data SVM:\n",
      "   feature_name  coefficient  abs_coefficient\n",
      "18       disc_3     4.620519         4.620519\n",
      "20    cat_0_Yes     4.286011         4.286011\n",
      "22    cat_2_Yes     4.213657         4.213657\n",
      "7        cont_7     4.066811         4.066811\n",
      "16       disc_1     3.695325         3.695325\n",
      "3        cont_3     3.489271         3.489271\n",
      "0        cont_0     3.370466         3.370466\n",
      "1        cont_1     1.606070         1.606070\n",
      "21    cat_1_Yes     1.570190         1.570190\n",
      "15       disc_0     1.458330         1.458330\n",
      "Predictions saved to results/classification/predictions_complete_None_SVM.csv\n"
     ]
    }
   ],
   "source": [
    "# SVM performance\n",
    "svm_complete_results = analyze_model_performance(\n",
    "    \"SVM\", best_svm_complete, X_train_complete, y_train_complete, X_test_complete, y_test_complete,\n",
    "    features, \"complete\", \"None\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54399c8e",
   "metadata": {},
   "source": [
    "# 1.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac5cb666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n",
      "\n",
      "Best parameters: {'bootstrap': True, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 30, 'min_samples_split': 50, 'n_estimators': 100, 'oob_score': True}\n",
      "Best cross-validation Accuracy: 0.8243\n"
     ]
    }
   ],
   "source": [
    "# Random Forest parameters for complete dataset\n",
    "param_grid_rf_complete = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'min_samples_split': [50, 100, 150],\n",
    "    'min_samples_leaf': [20, 30, 40],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True],                         \n",
    "    'oob_score': [True]\n",
    "}\n",
    "\n",
    "# train model\n",
    "rf_grid_complete = train_random_forest_model(X_train_complete, y_train_complete, param_grid_rf_complete, cv=10)\n",
    "best_rf_complete = rf_grid_complete.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "31f44cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of None imputed complete RandomForest:\n",
      "Accuracy: 0.8686, F1-Score: 0.8757\n",
      "\n",
      "Test performance of None imputed complete RandomForest:\n",
      "Accuracy: 0.7900, F1-Score: 0.8037\n",
      "\n",
      "Feature Importance for Complete Missing Data RandomForest:\n",
      "   feature_name  importance\n",
      "7        cont_7    0.269249\n",
      "3        cont_3    0.163734\n",
      "18       disc_3    0.141353\n",
      "0        cont_0    0.092660\n",
      "9        cont_9    0.070920\n",
      "16       disc_1    0.062508\n",
      "1        cont_1    0.054330\n",
      "11      cont_11    0.033219\n",
      "13      cont_13    0.033022\n",
      "20    cat_0_Yes    0.015484\n",
      "Predictions saved to results/classification/predictions_complete_None_RandomForest.csv\n"
     ]
    }
   ],
   "source": [
    "# Random Forest performance\n",
    "rf_complete_results = analyze_model_performance(\n",
    "    \"RandomForest\", best_rf_complete, X_train_complete, y_train_complete, X_test_complete, y_test_complete,\n",
    "    features, \"complete\", \"None\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1ad879",
   "metadata": {},
   "source": [
    "# 1.3 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff2a9748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "Best parameters: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01, 'max_iter': 2000}\n",
      "Best cross-validation Accuracy: 0.9614\n"
     ]
    }
   ],
   "source": [
    "# Neural Network parameters for complete dataset\n",
    "param_grid_nn_complete = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],  \n",
    "    'activation': ['relu', 'tanh', 'logistic'],                  \n",
    "    'alpha': [0.0001, 0.001, 0.01],                             \n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],                   \n",
    "    'max_iter': [2000, 3000]                                     \n",
    "}   \n",
    "\n",
    "# train model\n",
    "nn_grid_complete = train_neural_network_model(X_train_complete, y_train_complete, param_grid_nn_complete, cv=5)\n",
    "best_nn_complete = nn_grid_complete.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c78c3b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of None imputed complete NeuralNetwork:\n",
      "Accuracy: 1.0000, F1-Score: 1.0000\n",
      "\n",
      "Test performance of None imputed complete NeuralNetwork:\n",
      "Accuracy: 0.9733, F1-Score: 0.9742\n",
      "\n",
      "Feature Importance for Complete Missing Data NeuralNetwork:\n",
      "   feature_name  importance\n",
      "18       disc_3    0.162333\n",
      "7        cont_7    0.155333\n",
      "16       disc_1    0.133333\n",
      "3        cont_3    0.131000\n",
      "0        cont_0    0.127000\n",
      "20    cat_0_Yes    0.057000\n",
      "9        cont_9    0.047667\n",
      "22    cat_2_Yes    0.043000\n",
      "13      cont_13    0.041333\n",
      "11      cont_11    0.039667\n",
      "Predictions saved to results/classification/predictions_complete_None_NeuralNetwork.csv\n"
     ]
    }
   ],
   "source": [
    "# Neural Network performance\n",
    "nn_complete_results = analyze_model_performance(\n",
    "    \"NeuralNetwork\", best_nn_complete, X_train_complete, y_train_complete, X_test_complete, y_test_complete,\n",
    "    features, \"complete\", \"None\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b696530d",
   "metadata": {},
   "source": [
    "# 2. KNN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "396950f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load KNN datasets\n",
    "datasets = load_datasets(\"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42908909",
   "metadata": {},
   "source": [
    "# 2.1 SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80b96a3",
   "metadata": {},
   "source": [
    "## Low dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddbd3a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "\n",
      "Best parameters: {'C': 15, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best cross-validation Accuracy: 0.9157\n"
     ]
    }
   ],
   "source": [
    "# low dataset\n",
    "X_train_low, y_train_low, features = prepare_data(datasets[\"train_low\"])\n",
    "X_test_low, y_test_low, _ = prepare_data(datasets[\"test_low\"])\n",
    "\n",
    "# fine tune\n",
    "param_grid_svm_low = {\n",
    "    'C': [10, 15, 20, 25],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# train\n",
    "svm_grid_low = train_svm_model(X_train_low, y_train_low, param_grid_svm_low, cv=5)\n",
    "best_svm_low = svm_grid_low.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dcf98c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of KNN imputed low SVM:\n",
      "Accuracy: 0.9371, F1-Score: 0.9387\n",
      "\n",
      "Test performance of KNN imputed low SVM:\n",
      "Accuracy: 0.9433, F1-Score: 0.9453\n",
      "\n",
      "Feature Importance for Low Missing Data SVM:\n",
      "   feature_name  coefficient  abs_coefficient\n",
      "18       disc_3     2.217808         2.217808\n",
      "20    cat_0_Yes     2.158231         2.158231\n",
      "22    cat_2_Yes     2.057448         2.057448\n",
      "7        cont_7     2.020510         2.020510\n",
      "16       disc_1     1.938888         1.938888\n",
      "3        cont_3     1.795299         1.795299\n",
      "0        cont_0     1.786422         1.786422\n",
      "21    cat_1_Yes     1.086582         1.086582\n",
      "1        cont_1     0.776289         0.776289\n",
      "9        cont_9     0.760927         0.760927\n",
      "Predictions saved to results/classification/predictions_low_KNN_SVM.csv\n"
     ]
    }
   ],
   "source": [
    "# SVM performance\n",
    "svm_low_results = analyze_model_performance(\n",
    "    \"SVM\", best_svm_low, X_train_low, y_train_low, X_test_low, y_test_low,\n",
    "    features, \"low\", \"KNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc68a970",
   "metadata": {},
   "source": [
    "## High dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5fdd0345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "Best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best cross-validation Accuracy: 0.8357\n"
     ]
    }
   ],
   "source": [
    "# high dataset\n",
    "X_train_high, y_train_high, features = prepare_data(datasets[\"train_high\"])\n",
    "X_test_high, y_test_high, _ = prepare_data(datasets[\"test_high\"])\n",
    "\n",
    "# fine tune\n",
    "param_grid_svm_high = {\n",
    "    'C': [1, 2, 3, 4, 5],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# train\n",
    "svm_grid_high = train_svm_model(X_train_high, y_train_high, param_grid_svm_high, cv=5)\n",
    "best_svm_high = svm_grid_high.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d1dca110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of KNN imputed high SVM:\n",
      "Accuracy: 0.8543, F1-Score: 0.8555\n",
      "\n",
      "Test performance of KNN imputed high SVM:\n",
      "Accuracy: 0.8600, F1-Score: 0.8720\n",
      "\n",
      "Feature Importance for High Missing Data SVM:\n",
      "   feature_name  coefficient  abs_coefficient\n",
      "18       disc_3     1.009584         1.009584\n",
      "7        cont_7     1.004171         1.004171\n",
      "3        cont_3     0.989985         0.989985\n",
      "20    cat_0_Yes     0.914793         0.914793\n",
      "16       disc_1     0.893182         0.893182\n",
      "22    cat_2_Yes     0.865192         0.865192\n",
      "0        cont_0     0.741537         0.741537\n",
      "15       disc_0     0.593023         0.593023\n",
      "9        cont_9     0.464895         0.464895\n",
      "23    cat_3_Yes     0.434374         0.434374\n",
      "Predictions saved to results/classification/predictions_high_KNN_SVM.csv\n"
     ]
    }
   ],
   "source": [
    "# SVM performance\n",
    "svm_high_results = analyze_model_performance(\n",
    "    \"SVM\", best_svm_high, X_train_high, y_train_high, X_test_high, y_test_high,\n",
    "    features, \"high\", \"KNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd8a7d",
   "metadata": {},
   "source": [
    "# 2.2 Random Forest  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9985b2",
   "metadata": {},
   "source": [
    "## Low data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8e0456de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n",
      "\n",
      "Best parameters: {'bootstrap': True, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 20, 'min_samples_split': 100, 'n_estimators': 100, 'oob_score': True}\n",
      "Best cross-validation Accuracy: 0.8429\n"
     ]
    }
   ],
   "source": [
    "# low data\n",
    "param_grid_rf_low = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'min_samples_split': [50, 100, 150],\n",
    "    'min_samples_leaf': [20, 30, 40],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True],                         \n",
    "    'oob_score': [True]\n",
    "}\n",
    "\n",
    "# train\n",
    "rf_grid_low = train_random_forest_model(X_train_low, y_train_low, param_grid_rf_low, cv=10)\n",
    "best_rf_low = rf_grid_low.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "728d2ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of KNN imputed low RandomForest:\n",
      "Accuracy: 0.8829, F1-Score: 0.8871\n",
      "\n",
      "Test performance of KNN imputed low RandomForest:\n",
      "Accuracy: 0.7600, F1-Score: 0.7616\n",
      "\n",
      "Feature Importance for Low Missing Data RandomForest:\n",
      "   feature_name  importance\n",
      "7        cont_7    0.218401\n",
      "3        cont_3    0.173709\n",
      "0        cont_0    0.137404\n",
      "16       disc_1    0.110196\n",
      "18       disc_3    0.100170\n",
      "1        cont_1    0.080287\n",
      "9        cont_9    0.043076\n",
      "13      cont_13    0.027967\n",
      "11      cont_11    0.023298\n",
      "8        cont_8    0.010865\n",
      "Predictions saved to results/classification/predictions_low_KNN_RandomForest.csv\n"
     ]
    }
   ],
   "source": [
    "# Random Forest performance\n",
    "rf_low_results = analyze_model_performance(\n",
    "    \"RandomForest\", best_rf_low, X_train_low, y_train_low, X_test_low, y_test_low,\n",
    "    features, \"low\", \"KNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a6d205",
   "metadata": {},
   "source": [
    "## High data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "90d7848b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "Best parameters: {'bootstrap': True, 'class_weight': 'balanced', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 60, 'min_samples_split': 150, 'n_estimators': 150, 'oob_score': True}\n",
      "Best cross-validation Accuracy: 0.8514\n"
     ]
    }
   ],
   "source": [
    "# High data\n",
    "param_grid_rf_high = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [1, 2],\n",
    "    'min_samples_split': [150, 200, 250],\n",
    "    'min_samples_leaf': [60, 70, 80],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True],                         \n",
    "    'oob_score': [True],\n",
    "    'class_weight': ['balanced']    \n",
    "}\n",
    "\n",
    "# train Random forest\n",
    "rf_grid_high = train_random_forest_model(X_train_high, y_train_high, param_grid_rf_high, cv=10)\n",
    "best_rf_high = rf_grid_high.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9499b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of KNN imputed high RandomForest:\n",
      "Accuracy: 0.8814, F1-Score: 0.8836\n",
      "\n",
      "Test performance of KNN imputed high RandomForest:\n",
      "Accuracy: 0.6667, F1-Score: 0.6988\n",
      "\n",
      "Feature Importance for High Missing Data RandomForest:\n",
      "   feature_name  importance\n",
      "16       disc_1    0.197776\n",
      "7        cont_7    0.163061\n",
      "19       disc_4    0.128257\n",
      "3        cont_3    0.124208\n",
      "15       disc_0    0.110245\n",
      "5        cont_5    0.044456\n",
      "1        cont_1    0.043118\n",
      "18       disc_3    0.042804\n",
      "0        cont_0    0.036214\n",
      "9        cont_9    0.029671\n",
      "Predictions saved to results/classification/predictions_high_KNN_RandomForest.csv\n"
     ]
    }
   ],
   "source": [
    "# Random Forest performance\n",
    "rf_high_results = analyze_model_performance(\n",
    "    \"RandomForest\", best_rf_high, X_train_high, y_train_high, X_test_high, y_test_high,\n",
    "    features, \"high\", \"KNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a923a",
   "metadata": {},
   "source": [
    "## 2.3 Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0bc99d",
   "metadata": {},
   "source": [
    "## Low Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "292517e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "Best parameters: {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (50, 50), 'learning_rate_init': 0.001, 'max_iter': 2000}\n",
      "Best cross-validation Accuracy: 0.9071\n"
     ]
    }
   ],
   "source": [
    "# low data\n",
    "param_grid_nn_low = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],  \n",
    "    'activation': ['relu', 'tanh', 'logistic'],                               \n",
    "    'alpha': [0.0001, 0.001, 0.01],                             \n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],                        \n",
    "    'max_iter': [2000, 3000]                                                \n",
    "}\n",
    "\n",
    "# train Neural Network \n",
    "nn_grid_low = train_neural_network_model(X_train_low, y_train_low, param_grid_nn_low, cv=5)\n",
    "best_nn_low = nn_grid_low.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45600302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of KNN imputed low NeuralNetwork:\n",
      "Accuracy: 0.9343, F1-Score: 0.9356\n",
      "\n",
      "Test performance of KNN imputed low NeuralNetwork:\n",
      "Accuracy: 0.9300, F1-Score: 0.9325\n",
      "\n",
      "Feature Importance for Low Missing Data NeuralNetwork:\n",
      "   feature_name  importance\n",
      "18       disc_3    0.147000\n",
      "7        cont_7    0.127333\n",
      "16       disc_1    0.114667\n",
      "3        cont_3    0.099000\n",
      "0        cont_0    0.091333\n",
      "22    cat_2_Yes    0.040000\n",
      "20    cat_0_Yes    0.037333\n",
      "9        cont_9    0.032000\n",
      "13      cont_13    0.026667\n",
      "15       disc_0    0.025000\n",
      "Predictions saved to results/classification/predictions_low_KNN_NeuralNetwork.csv\n"
     ]
    }
   ],
   "source": [
    "# Neural Network performance\n",
    "nn_low_results = analyze_model_performance(\n",
    "    \"NeuralNetwork\", best_nn_low, X_train_low, y_train_low, X_test_low, y_test_low,\n",
    "    features, \"low\", \"KNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4d3666",
   "metadata": {},
   "source": [
    "## KNN Neural Network High Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e3c0bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "Best parameters: {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001, 'max_iter': 2000}\n",
      "Best cross-validation Accuracy: 0.8357\n"
     ]
    }
   ],
   "source": [
    "# high data\n",
    "param_grid_nn_high = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],  \n",
    "    'activation': ['relu', 'tanh', 'logistic'],                  \n",
    "    'alpha': [0.0001, 0.001, 0.01],                             \n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],                   \n",
    "    'max_iter': [2000, 3000]                                     \n",
    "}\n",
    "\n",
    "# train Neural Network \n",
    "nn_grid_high = train_neural_network_model(X_train_high, y_train_high, param_grid_nn_high, cv=5)\n",
    "best_nn_high = nn_grid_high.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "14ec2f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of KNN imputed high NeuralNetwork:\n",
      "Accuracy: 0.8557, F1-Score: 0.8583\n",
      "\n",
      "Test performance of KNN imputed high NeuralNetwork:\n",
      "Accuracy: 0.8467, F1-Score: 0.8623\n",
      "\n",
      "Feature Importance for High Missing Data NeuralNetwork:\n",
      "   feature_name  importance\n",
      "18       disc_3    0.124333\n",
      "7        cont_7    0.113333\n",
      "3        cont_3    0.049333\n",
      "16       disc_1    0.040667\n",
      "9        cont_9    0.032667\n",
      "0        cont_0    0.025667\n",
      "13      cont_13    0.020000\n",
      "22    cat_2_Yes    0.013000\n",
      "20    cat_0_Yes    0.012667\n",
      "15       disc_0    0.007000\n",
      "Predictions saved to results/classification/predictions_high_KNN_NeuralNetwork.csv\n"
     ]
    }
   ],
   "source": [
    "# Neural Network performance\n",
    "nn_high_results = analyze_model_performance(\n",
    "    \"NeuralNetwork\", best_nn_high, X_train_high, y_train_high, X_test_high, y_test_high,\n",
    "    features, \"high\", \"KNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e41e15c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "KNN imputation classification summary\n",
      "\n",
      "================================================================================\n",
      "\n",
      "KNN Imputation Classification performance summary:\n",
      "         Dataset     Classifier  Train_Accuracy  Train_F1  Test_Accuracy  Test_F1\n",
      " KNN_Low_Missing            SVM          0.9371    0.9387         0.9433   0.9453\n",
      "KNN_High_Missing            SVM          0.8543    0.8555         0.8600   0.8720\n",
      " KNN_Low_Missing  Random_Forest          0.8829    0.8871         0.7600   0.7616\n",
      "KNN_High_Missing  Random_Forest          0.8814    0.8836         0.6667   0.6988\n",
      " KNN_Low_Missing Neural_Network          0.9343    0.9356         0.9300   0.9325\n",
      "KNN_High_Missing Neural_Network          0.8557    0.8583         0.8467   0.8623\n",
      "Complete_Dataset            SVM          0.9843    0.9846         0.9767   0.9773\n",
      "Complete_Dataset  Random_Forest          0.8686    0.8757         0.7900   0.8037\n",
      "Complete_Dataset Neural_Network          1.0000    1.0000         0.9733   0.9742\n",
      "\n",
      "================================================================================\n",
      "Test Accuracy by Dataset and Classifier\n",
      "\n",
      "================================================================================\n",
      "Classifier        Neural_Network  Random_Forest     SVM\n",
      "Dataset                                                \n",
      "Complete_Dataset          0.9733         0.7900  0.9767\n",
      "KNN_High_Missing          0.8467         0.6667  0.8600\n",
      "KNN_Low_Missing           0.9300         0.7600  0.9433\n",
      "\n",
      "================================================================================\n",
      "Test F1 Score by Dataset and Classifier\n",
      "\n",
      "================================================================================\n",
      "Classifier        Neural_Network  Random_Forest     SVM\n",
      "Dataset                                                \n",
      "Complete_Dataset          0.9742         0.8037  0.9773\n",
      "KNN_High_Missing          0.8623         0.6988  0.8720\n",
      "KNN_Low_Missing           0.9325         0.7616  0.9453\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KNN imputation classification summary\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "knn_results_summary = [\n",
    "    # SVM \n",
    "    {\n",
    "        'Dataset': 'KNN_Low_Missing',\n",
    "        'Classifier': 'SVM',\n",
    "        'Train_Accuracy': svm_low_results['results']['train_accuracy'],\n",
    "        'Train_F1': svm_low_results['results']['train_f1'],\n",
    "        'Test_Accuracy': svm_low_results['results']['test_accuracy'],\n",
    "        'Test_F1': svm_low_results['results']['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'KNN_High_Missing',\n",
    "        'Classifier': 'SVM',\n",
    "        'Train_Accuracy': svm_high_results['results']['train_accuracy'],\n",
    "        'Train_F1': svm_high_results['results']['train_f1'],\n",
    "        'Test_Accuracy': svm_high_results['results']['test_accuracy'],\n",
    "        'Test_F1': svm_high_results['results']['test_f1']\n",
    "    },\n",
    "    # Random Forest \n",
    "    {\n",
    "        'Dataset': 'KNN_Low_Missing',\n",
    "        'Classifier': 'Random_Forest',\n",
    "        'Train_Accuracy': rf_low_results['results']['train_accuracy'],\n",
    "        'Train_F1': rf_low_results['results']['train_f1'],\n",
    "        'Test_Accuracy': rf_low_results['results']['test_accuracy'],\n",
    "        'Test_F1': rf_low_results['results']['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'KNN_High_Missing',\n",
    "        'Classifier': 'Random_Forest',\n",
    "        'Train_Accuracy': rf_high_results['results']['train_accuracy'],\n",
    "        'Train_F1': rf_high_results['results']['train_f1'],\n",
    "        'Test_Accuracy': rf_high_results['results']['test_accuracy'],\n",
    "        'Test_F1': rf_high_results['results']['test_f1']\n",
    "    },\n",
    "    # Neural Network \n",
    "    {\n",
    "        'Dataset': 'KNN_Low_Missing',\n",
    "        'Classifier': 'Neural_Network',\n",
    "        'Train_Accuracy': nn_low_results['results']['train_accuracy'],\n",
    "        'Train_F1': nn_low_results['results']['train_f1'],\n",
    "        'Test_Accuracy': nn_low_results['results']['test_accuracy'],\n",
    "        'Test_F1': nn_low_results['results']['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'KNN_High_Missing',\n",
    "        'Classifier': 'Neural_Network',\n",
    "        'Train_Accuracy': nn_high_results['results']['train_accuracy'],\n",
    "        'Train_F1': nn_high_results['results']['train_f1'],\n",
    "        'Test_Accuracy': nn_high_results['results']['test_accuracy'],\n",
    "        'Test_F1': nn_high_results['results']['test_f1']\n",
    "    },\n",
    "    # Complete \n",
    "    {\n",
    "        'Dataset': 'Complete_Dataset',\n",
    "        'Classifier': 'SVM',\n",
    "        'Train_Accuracy': svm_complete_results['results']['train_accuracy'],\n",
    "        'Train_F1': svm_complete_results['results']['train_f1'],\n",
    "        'Test_Accuracy': svm_complete_results['results']['test_accuracy'],\n",
    "        'Test_F1': svm_complete_results['results']['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Complete_Dataset',\n",
    "        'Classifier': 'Random_Forest',\n",
    "        'Train_Accuracy': rf_complete_results['results']['train_accuracy'],\n",
    "        'Train_F1': rf_complete_results['results']['train_f1'],\n",
    "        'Test_Accuracy': rf_complete_results['results']['test_accuracy'],\n",
    "        'Test_F1': rf_complete_results['results']['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Complete_Dataset',\n",
    "        'Classifier': 'Neural_Network',\n",
    "        'Train_Accuracy': nn_complete_results['results']['train_accuracy'],\n",
    "        'Train_F1': nn_complete_results['results']['train_f1'],\n",
    "        'Test_Accuracy': nn_complete_results['results']['test_accuracy'],\n",
    "        'Test_F1': nn_complete_results['results']['test_f1']\n",
    "    }\n",
    "]\n",
    "\n",
    "knn_results_df = pd.DataFrame(knn_results_summary)\n",
    "knn_results_df = knn_results_df.round(4)\n",
    "\n",
    "print(\"\\nKNN Imputation Classification performance summary:\")\n",
    "print(knn_results_df.to_string(index=False))\n",
    "\n",
    "# pivot tables\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Test Accuracy by Dataset and Classifier\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "pivot_accuracy = knn_results_df.pivot(index='Dataset', columns='Classifier', values='Test_Accuracy')\n",
    "print(pivot_accuracy.round(4))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Test F1 Score by Dataset and Classifier\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "pivot_f1 = knn_results_df.pivot(index='Dataset', columns='Classifier', values='Test_F1')\n",
    "print(pivot_f1.round(4))\n",
    "\n",
    "# save results\n",
    "knn_results_df.to_csv('results/classification/knn_classification_results.csv', index=False)\n",
    "pivot_accuracy.to_csv('results/classification/knn_accuracy_pivot.csv')\n",
    "pivot_f1.to_csv('results/classification/knn_f1_pivot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba2808f",
   "metadata": {},
   "source": [
    "# 3. MICE imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f42c8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MICE datasets\n",
    "datasets = load_datasets(\"MICE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34cf4bd",
   "metadata": {},
   "source": [
    "# 3.1 SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ed19a",
   "metadata": {},
   "source": [
    "## Low dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2e6a3192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "\n",
      "Best parameters: {'C': 2, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best cross-validation Accuracy: 0.9357\n"
     ]
    }
   ],
   "source": [
    "X_train_low, y_train_low, features = prepare_data(datasets[\"train_low\"])\n",
    "X_test_low, y_test_low, _ = prepare_data(datasets[\"test_low\"])\n",
    "\n",
    "# fine tune\n",
    "param_grid_svm_low = {\n",
    "    'C': [2, 5, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# train\n",
    "svm_grid_low = train_svm_model(X_train_low, y_train_low, param_grid_svm_low, cv=10)\n",
    "best_svm_low = svm_grid_low.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6997ee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of MICE imputed low SVM:\n",
      "Accuracy: 0.9514, F1-Score: 0.9529\n",
      "\n",
      "Test performance of MICE imputed low SVM:\n",
      "Accuracy: 0.9500, F1-Score: 0.9518\n",
      "\n",
      "Feature Importance for Low Missing Data SVM:\n",
      "   feature_name  coefficient  abs_coefficient\n",
      "18       disc_3     2.077493         2.077493\n",
      "20    cat_0_Yes     2.064850         2.064850\n",
      "7        cont_7     1.915327         1.915327\n",
      "22    cat_2_Yes     1.866358         1.866358\n",
      "0        cont_0     1.724938         1.724938\n",
      "16       disc_1     1.716302         1.716302\n",
      "3        cont_3     1.693588         1.693588\n",
      "21    cat_1_Yes     0.849451         0.849451\n",
      "1        cont_1     0.724008         0.724008\n",
      "13      cont_13     0.700471         0.700471\n",
      "Predictions saved to results/classification/predictions_low_MICE_SVM.csv\n"
     ]
    }
   ],
   "source": [
    "# SVM performance\n",
    "svm_low_results = analyze_model_performance(\n",
    "    \"SVM\", best_svm_low, X_train_low, y_train_low, X_test_low, y_test_low,\n",
    "    features, \"low\", \"MICE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922d8665",
   "metadata": {},
   "source": [
    "## High dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aa7ceb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "\n",
      "Best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best cross-validation Accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "X_train_high, y_train_high, features = prepare_data(datasets[\"train_high\"])\n",
    "X_test_high, y_test_high, _ = prepare_data(datasets[\"test_high\"])\n",
    "\n",
    "# fine tuning\n",
    "param_grid_svm_high = {\n",
    "    'C': [1, 2, 3, 4, 5],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# train SVM\n",
    "svm_grid_high = train_svm_model(X_train_high, y_train_high, param_grid_svm_high, cv=10)\n",
    "best_svm_high = svm_grid_high.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c8adbc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of MICE imputed high SVM:\n",
      "Accuracy: 0.9600, F1-Score: 0.9614\n",
      "\n",
      "Test performance of MICE imputed high SVM:\n",
      "Accuracy: 0.8200, F1-Score: 0.8269\n",
      "\n",
      "Feature Importance for High Missing Data SVM:\n",
      "   feature_name  coefficient  abs_coefficient\n",
      "3        cont_3     2.045080         2.045080\n",
      "16       disc_1     1.872073         1.872073\n",
      "7        cont_7     1.598041         1.598041\n",
      "20    cat_0_Yes     1.504586         1.504586\n",
      "0        cont_0     1.408046         1.408046\n",
      "18       disc_3     1.402328         1.402328\n",
      "17       disc_2    -1.215791         1.215791\n",
      "22    cat_2_Yes     1.192336         1.192336\n",
      "15       disc_0     1.096440         1.096440\n",
      "9        cont_9     0.940989         0.940989\n",
      "Predictions saved to results/classification/predictions_high_MICE_SVM.csv\n"
     ]
    }
   ],
   "source": [
    "# SVM performance\n",
    "svm_high_results = analyze_model_performance(\n",
    "    \"SVM\", best_svm_high, X_train_high, y_train_high, X_test_high, y_test_high,\n",
    "    features, \"high\", \"MICE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2922bd",
   "metadata": {},
   "source": [
    "# 3.2 Random Forest  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfca61b2",
   "metadata": {},
   "source": [
    "## Low data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f3ffc2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Best parameters: {'bootstrap': True, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 30, 'min_samples_split': 50, 'n_estimators': 100, 'oob_score': True}\n",
      "Best cross-validation Accuracy: 0.8043\n"
     ]
    }
   ],
   "source": [
    "# Random Forest low data\n",
    "param_grid_rf_low = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [50, 100, 150],\n",
    "    'min_samples_leaf': [30, 40, 50],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True],                         \n",
    "    'oob_score': [True]\n",
    "}\n",
    "\n",
    "# train Random Forest \n",
    "rf_grid_low = train_random_forest_model(X_train_low, y_train_low, param_grid_rf_low, cv=10)\n",
    "best_rf_low = rf_grid_low.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a776f2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of MICE imputed low RandomForest:\n",
      "Accuracy: 0.8743, F1-Score: 0.8820\n",
      "\n",
      "Test performance of MICE imputed low RandomForest:\n",
      "Accuracy: 0.8033, F1-Score: 0.8162\n",
      "\n",
      "Feature Importance for Low Missing Data RandomForest:\n",
      "   feature_name  importance\n",
      "7        cont_7    0.250234\n",
      "18       disc_3    0.139848\n",
      "3        cont_3    0.137174\n",
      "0        cont_0    0.121853\n",
      "9        cont_9    0.059699\n",
      "16       disc_1    0.056162\n",
      "13      cont_13    0.046129\n",
      "1        cont_1    0.043085\n",
      "11      cont_11    0.033467\n",
      "8        cont_8    0.018916\n",
      "Predictions saved to results/classification/predictions_low_MICE_RandomForest.csv\n"
     ]
    }
   ],
   "source": [
    "# Random Forest performance\n",
    "rf_low_results = analyze_model_performance(\n",
    "    \"RandomForest\", best_rf_low, X_train_low, y_train_low, X_test_low, y_test_low,\n",
    "    features, \"low\", \"MICE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eebfe38",
   "metadata": {},
   "source": [
    "## MICE Random Forest High data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "32a506cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Best parameters: {'bootstrap': True, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 40, 'min_samples_split': 50, 'n_estimators': 150, 'oob_score': True}\n",
      "Best cross-validation Accuracy: 0.8086\n"
     ]
    }
   ],
   "source": [
    "# high dataset\n",
    "param_grid_rf_high = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [50, 100, 150],\n",
    "    'min_samples_leaf': [30, 40, 50],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True],                         \n",
    "    'oob_score': [True]   \n",
    "}\n",
    "\n",
    "# train Random Forest \n",
    "rf_grid_high = train_random_forest_model(X_train_high, y_train_high, param_grid_rf_high, cv=10)\n",
    "best_rf_high = rf_grid_high.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a2196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of MICE imputed high RandomForest:\n",
      "Accuracy: 0.8714, F1-Score: 0.8767\n",
      "\n",
      "Test performance of MICE imputed high RandomForest:\n",
      "Accuracy: 0.8033, F1-Score: 0.8127\n",
      "\n",
      "Feature Importance for High Missing Data RandomForest:\n",
      "   feature_name  importance\n",
      "7        cont_7    0.262234\n",
      "18       disc_3    0.138783\n",
      "3        cont_3    0.109310\n",
      "1        cont_1    0.071751\n",
      "0        cont_0    0.070087\n",
      "9        cont_9    0.064326\n",
      "16       disc_1    0.051261\n",
      "15       disc_0    0.043541\n",
      "11      cont_11    0.041286\n",
      "13      cont_13    0.033040\n",
      "Predictions saved to results/classification/predictions_high_MICE_RandomForest.csv\n"
     ]
    }
   ],
   "source": [
    "# Random Forest performance\n",
    "rf_high_results = analyze_model_performance(\n",
    "    \"RandomForest\", best_rf_high, X_train_high, y_train_high, X_test_high, y_test_high,\n",
    "    features, \"high\", \"MICE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4ea638",
   "metadata": {},
   "source": [
    "## 3.3 Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483514a0",
   "metadata": {},
   "source": [
    "## Low Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "81dbbf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "Best parameters: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate_init': 0.01, 'max_iter': 2000}\n",
      "Best cross-validation Accuracy: 0.9314\n"
     ]
    }
   ],
   "source": [
    "# Neural Network - low dataset\n",
    "param_grid_nn_low = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],  \n",
    "    'activation': ['relu', 'tanh', 'logistic'],                               \n",
    "    'alpha': [0.0001, 0.001, 0.01],                             \n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],                        \n",
    "    'max_iter': [2000, 3000]                                                \n",
    "}\n",
    "\n",
    "# train Neural Network \n",
    "nn_grid_low = train_neural_network_model(X_train_low, y_train_low, param_grid_nn_low, cv=5)\n",
    "best_nn_low = nn_grid_low.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7bc9b0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of MICE imputed low NeuralNetwork:\n",
      "Accuracy: 1.0000, F1-Score: 1.0000\n",
      "\n",
      "Test performance of MICE imputed low NeuralNetwork:\n",
      "Accuracy: 0.9500, F1-Score: 0.9511\n",
      "\n",
      "Feature Importance for Low Missing Data NeuralNetwork:\n",
      "   feature_name  importance\n",
      "18       disc_3    0.141000\n",
      "7        cont_7    0.125333\n",
      "0        cont_0    0.105000\n",
      "3        cont_3    0.101333\n",
      "16       disc_1    0.100000\n",
      "20    cat_0_Yes    0.046667\n",
      "22    cat_2_Yes    0.037000\n",
      "1        cont_1    0.029667\n",
      "11      cont_11    0.022333\n",
      "5        cont_5    0.020000\n",
      "Predictions saved to results/classification/predictions_low_MICE_NeuralNetwork.csv\n"
     ]
    }
   ],
   "source": [
    "# Neural Network performance\n",
    "nn_low_results = analyze_model_performance(\n",
    "    \"NeuralNetwork\", best_nn_low, X_train_low, y_train_low, X_test_low, y_test_low,\n",
    "    features, \"low\", \"MICE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb4fbea",
   "metadata": {},
   "source": [
    "## High Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3dd7a127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      "Best parameters: {'activation': 'relu', 'alpha': 2.0, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01, 'max_iter': 2000}\n",
      "Best cross-validation Accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "# Neural Network - high dataset\n",
    "param_grid_nn_high = {\n",
    "    'hidden_layer_sizes': [(10,), (15,)],  \n",
    "    'activation': ['relu', 'tanh', 'logistic'],                  \n",
    "    'alpha': [1.0, 2.0, 5.0],                             \n",
    "    'learning_rate_init': [0.001, 0.01],                   \n",
    "    'max_iter': [2000, 3000]                                     \n",
    "}\n",
    "\n",
    "# train Neural Network \n",
    "nn_grid_high = train_neural_network_model(X_train_high, y_train_high, param_grid_nn_high, cv=5)\n",
    "best_nn_high = nn_grid_high.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c5c53016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of MICE imputed high NeuralNetwork:\n",
      "Accuracy: 0.9557, F1-Score: 0.9570\n",
      "\n",
      "Test performance of MICE imputed high NeuralNetwork:\n",
      "Accuracy: 0.8233, F1-Score: 0.8307\n",
      "\n",
      "Feature Importance for High Missing Data NeuralNetwork:\n",
      "   feature_name  importance\n",
      "16       disc_1    0.082000\n",
      "18       disc_3    0.078000\n",
      "0        cont_0    0.074000\n",
      "3        cont_3    0.069667\n",
      "7        cont_7    0.064667\n",
      "15       disc_0    0.029333\n",
      "9        cont_9    0.027333\n",
      "22    cat_2_Yes    0.013333\n",
      "20    cat_0_Yes    0.012667\n",
      "13      cont_13    0.004667\n",
      "Predictions saved to results/classification/predictions_high_MICE_NeuralNetwork.csv\n"
     ]
    }
   ],
   "source": [
    "# Neural Network performance\n",
    "nn_high_results = analyze_model_performance(\n",
    "    \"NeuralNetwork\", best_nn_high, X_train_high, y_train_high, X_test_high, y_test_high,\n",
    "    features, \"high\", \"MICE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337ba176",
   "metadata": {},
   "source": [
    "# MICE imputation results for all classification methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "162b819e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MICE IMPUTATION RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "MICE Imputation Classification performance summary:\n",
      "          Dataset     Classifier  Train_Accuracy  Train_F1  Test_Accuracy  Test_F1\n",
      " MICE_Low_Missing            SVM          0.9514    0.9529         0.9500   0.9518\n",
      "MICE_High_Missing            SVM          0.9600    0.9614         0.8200   0.8269\n",
      " MICE_Low_Missing  Random_Forest          0.8743    0.8820         0.8033   0.8162\n",
      "MICE_High_Missing  Random_Forest          0.8714    0.8767         0.8033   0.8127\n",
      " MICE_Low_Missing Neural_Network          1.0000    1.0000         0.9500   0.9511\n",
      "MICE_High_Missing Neural_Network          0.9557    0.9570         0.8233   0.8307\n",
      " Complete_Dataset            SVM          0.9843    0.9846         0.9767   0.9773\n",
      " Complete_Dataset  Random_Forest          0.8686    0.8757         0.7900   0.8037\n",
      " Complete_Dataset Neural_Network          1.0000    1.0000         0.9733   0.9742\n",
      "================================================================================\n",
      "Test Accuracy by Dataset and Classifier\n",
      "================================================================================\n",
      "Classifier         Neural_Network  Random_Forest     SVM\n",
      "Dataset                                                 \n",
      "Complete_Dataset           0.9733         0.7900  0.9767\n",
      "MICE_High_Missing          0.8233         0.8033  0.8200\n",
      "MICE_Low_Missing           0.9500         0.8033  0.9500\n",
      "================================================================================\n",
      "Test F1 Score by Dataset and Classifier\n",
      "================================================================================\n",
      "Classifier         Neural_Network  Random_Forest     SVM\n",
      "Dataset                                                 \n",
      "Complete_Dataset           0.9742         0.8037  0.9773\n",
      "MICE_High_Missing          0.8307         0.8127  0.8269\n",
      "MICE_Low_Missing           0.9511         0.8162  0.9518\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"MICE IMPUTATION RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "mice_results_summary = [\n",
    "    # SVM \n",
    "    {\n",
    "        'Dataset': 'MICE_Low_Missing',\n",
    "        'Classifier': 'SVM',\n",
    "        'Train_Accuracy': svm_low_results['results']['train_accuracy'],\n",
    "        'Train_F1': svm_low_results['results']['train_f1'],\n",
    "        'Test_Accuracy': svm_low_results['results']['test_accuracy'],\n",
    "        'Test_F1': svm_low_results['results']['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'MICE_High_Missing',\n",
    "        'Classifier': 'SVM',\n",
    "        'Train_Accuracy': svm_high_results['results']['train_accuracy'],\n",
    "        'Train_F1': svm_high_results['results']['train_f1'],\n",
    "        'Test_Accuracy': svm_high_results['results']['test_accuracy'],\n",
    "        'Test_F1': svm_high_results['results']['test_f1']\n",
    "    },\n",
    "    # Random Forest \n",
    "    {\n",
    "        'Dataset': 'MICE_Low_Missing',\n",
    "        'Classifier': 'Random_Forest',\n",
    "        'Train_Accuracy': rf_low_results['results']['train_accuracy'],\n",
    "        'Train_F1': rf_low_results['results']['train_f1'],\n",
    "        'Test_Accuracy': rf_low_results['results']['test_accuracy'],\n",
    "        'Test_F1': rf_low_results['results']['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'MICE_High_Missing',\n",
    "        'Classifier': 'Random_Forest',\n",
    "        'Train_Accuracy': rf_high_results['results']['train_accuracy'],\n",
    "        'Train_F1': rf_high_results['results']['train_f1'],\n",
    "        'Test_Accuracy': rf_high_results['results']['test_accuracy'],\n",
    "        'Test_F1': rf_high_results['results']['test_f1']\n",
    "        },\n",
    "    # Neural Network \n",
    "    {\n",
    "        'Dataset': 'MICE_Low_Missing',\n",
    "        'Classifier': 'Neural_Network',\n",
    "        'Train_Accuracy': nn_low_results['results']['train_accuracy'],\n",
    "        'Train_F1': nn_low_results['results']['train_f1'],\n",
    "        'Test_Accuracy': nn_low_results['results']['test_accuracy'],\n",
    "        'Test_F1': nn_low_results['results']['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'MICE_High_Missing',\n",
    "        'Classifier': 'Neural_Network',\n",
    "        'Train_Accuracy': nn_high_results['results']['train_accuracy'],\n",
    "        'Train_F1': nn_high_results['results']['train_f1'],\n",
    "        'Test_Accuracy': nn_high_results['results']['test_accuracy'],\n",
    "        'Test_F1': nn_high_results['results']['test_f1']\n",
    "    },\n",
    "    # Complete dataset results \n",
    "    {\n",
    "        'Dataset': 'Complete_Dataset',\n",
    "        'Classifier': 'SVM',\n",
    "        'Train_Accuracy': svm_complete_results['results']['train_accuracy'],\n",
    "        'Train_F1': svm_complete_results['results']['train_f1'],\n",
    "        'Test_Accuracy': svm_complete_results['results']['test_accuracy'],\n",
    "        'Test_F1': svm_complete_results['results']['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Complete_Dataset',\n",
    "        'Classifier': 'Random_Forest',\n",
    "        'Train_Accuracy': rf_complete_results['results']['train_accuracy'],\n",
    "        'Train_F1': rf_complete_results['results']['train_f1'],\n",
    "        'Test_Accuracy': rf_complete_results['results']['test_accuracy'],\n",
    "        'Test_F1': rf_complete_results['results']['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Complete_Dataset',\n",
    "        'Classifier': 'Neural_Network',\n",
    "        'Train_Accuracy': nn_complete_results['results']['train_accuracy'],\n",
    "        'Train_F1': nn_complete_results['results']['train_f1'],\n",
    "        'Test_Accuracy': nn_complete_results['results']['test_accuracy'],\n",
    "        'Test_F1': nn_complete_results['results']['test_f1']\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "mice_results_df = pd.DataFrame(mice_results_summary)\n",
    "mice_results_df = mice_results_df.round(4)\n",
    "\n",
    "print(\"\\nMICE Imputation Classification performance summary:\")\n",
    "print(mice_results_df.to_string(index=False))\n",
    "\n",
    "# pivot tables\n",
    "print(\"=\" * 80)\n",
    "print(\"Test Accuracy by Dataset and Classifier\")\n",
    "print(\"=\" * 80)\n",
    "pivot_accuracy = mice_results_df.pivot(index='Dataset', columns='Classifier', values='Test_Accuracy')\n",
    "print(pivot_accuracy.round(4))\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Test F1 Score by Dataset and Classifier\")\n",
    "print(\"=\" * 80)\n",
    "pivot_f1 = mice_results_df.pivot(index='Dataset', columns='Classifier', values='Test_F1')\n",
    "print(pivot_f1.round(4))\n",
    "\n",
    "# save results\n",
    "mice_results_df.to_csv('results/classification/mice_classification_results.csv', index=False)\n",
    "pivot_accuracy.to_csv('results/classification/mice_accuracy_pivot.csv')\n",
    "pivot_f1.to_csv('results/classification/mice_f1_pivot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd28727",
   "metadata": {},
   "source": [
    "# 4. Simple Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "61f52601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Simple imputed datasets\n",
    "datasets = load_datasets(\"Simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45797280",
   "metadata": {},
   "source": [
    "# 4.1 SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b02cc",
   "metadata": {},
   "source": [
    "# Low data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8d6a8f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "Best parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best cross-validation Accuracy: 0.8814\n"
     ]
    }
   ],
   "source": [
    "X_train_low, y_train_low, features = prepare_data(datasets[\"train_low\"])\n",
    "X_test_low, y_test_low, _ = prepare_data(datasets[\"test_low\"])\n",
    "\n",
    "# fine tuning\n",
    "param_grid_svm_low = {\n",
    "    'C': [2, 5, 10, 15, 20, 25],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# train SVM model\n",
    "svm_grid_low = train_svm_model(X_train_low, y_train_low, param_grid_svm_low, cv=5)\n",
    "best_svm_low = svm_grid_low.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ce861edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of Simple imputed low SVM:\n",
      "Accuracy: 0.9071, F1-Score: 0.9096\n",
      "\n",
      "Test performance of Simple imputed low SVM:\n",
      "Accuracy: 0.9500, F1-Score: 0.9515\n",
      "\n",
      "Feature Importance for Low Missing Data SVM:\n",
      "   feature_name  coefficient  abs_coefficient\n",
      "18       disc_3     1.616319         1.616319\n",
      "7        cont_7     1.580065         1.580065\n",
      "20    cat_0_Yes     1.467887         1.467887\n",
      "16       disc_1     1.457456         1.457456\n",
      "22    cat_2_Yes     1.453295         1.453295\n",
      "0        cont_0     1.324782         1.324782\n",
      "3        cont_3     1.300425         1.300425\n",
      "21    cat_1_Yes     0.646626         0.646626\n",
      "13      cont_13     0.620832         0.620832\n",
      "9        cont_9     0.617603         0.617603\n",
      "Predictions saved to results/classification/predictions_low_Simple_SVM.csv\n"
     ]
    }
   ],
   "source": [
    "# SVM performance\n",
    "svm_low_results = analyze_model_performance(\n",
    "    \"SVM\", best_svm_low, X_train_low, y_train_low, X_test_low, y_test_low,\n",
    "    features, \"low\", \"Simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d43b44",
   "metadata": {},
   "source": [
    "# High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c4d44727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "Best parameters: {'C': 3, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best cross-validation Accuracy: 0.8157\n"
     ]
    }
   ],
   "source": [
    "X_train_high, y_train_high, features = prepare_data(datasets[\"train_high\"])\n",
    "X_test_high, y_test_high, _ = prepare_data(datasets[\"test_high\"])\n",
    "\n",
    "# fine tuning SVM\n",
    "param_grid_svm_high = {\n",
    "    'C': [1, 2, 3, 4, 5],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# train SVM \n",
    "svm_grid_high = train_svm_model(X_train_high, y_train_high, param_grid_svm_high, cv=5)\n",
    "best_svm_high = svm_grid_high.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d4ee41c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of Simple imputed high SVM:\n",
      "Accuracy: 0.8386, F1-Score: 0.8388\n",
      "\n",
      "Test performance of Simple imputed high SVM:\n",
      "Accuracy: 0.8800, F1-Score: 0.8882\n",
      "\n",
      "Feature Importance for High Missing Data SVM:\n",
      "   feature_name  coefficient  abs_coefficient\n",
      "18       disc_3     1.115167         1.115167\n",
      "7        cont_7     1.108995         1.108995\n",
      "20    cat_0_Yes     1.083222         1.083222\n",
      "16       disc_1     0.917040         0.917040\n",
      "3        cont_3     0.895048         0.895048\n",
      "0        cont_0     0.887821         0.887821\n",
      "22    cat_2_Yes     0.815311         0.815311\n",
      "9        cont_9     0.514801         0.514801\n",
      "15       disc_0     0.485869         0.485869\n",
      "23    cat_3_Yes     0.439827         0.439827\n",
      "Predictions saved to results/classification/predictions_high_Simple_SVM.csv\n"
     ]
    }
   ],
   "source": [
    "# SVM performance\n",
    "svm_high_results = analyze_model_performance(\n",
    "    \"SVM\", best_svm_high, X_train_high, y_train_high, X_test_high, y_test_high,\n",
    "    features, \"high\", \"Simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d064f4",
   "metadata": {},
   "source": [
    "# 4.2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8a036d",
   "metadata": {},
   "source": [
    "# Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b4b22225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n",
      "\n",
      "Best parameters: {'bootstrap': True, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 20, 'min_samples_split': 100, 'n_estimators': 100, 'oob_score': True}\n",
      "Best cross-validation Accuracy: 0.7914\n"
     ]
    }
   ],
   "source": [
    "# Random Forest - low data\n",
    "param_grid_rf_low = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'min_samples_split': [50, 100, 150],\n",
    "    'min_samples_leaf': [20, 30, 40],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True],                         \n",
    "    'oob_score': [True]\n",
    "}\n",
    "\n",
    "# train Random Forest \n",
    "rf_grid_low = train_random_forest_model(X_train_low, y_train_low, param_grid_rf_low, cv=10)\n",
    "best_rf_low = rf_grid_low.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a96134e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of Simple imputed low RandomForest:\n",
      "Accuracy: 0.8386, F1-Score: 0.8487\n",
      "\n",
      "Test performance of Simple imputed low RandomForest:\n",
      "Accuracy: 0.7800, F1-Score: 0.7885\n",
      "\n",
      "Feature Importance for Low Missing Data RandomForest:\n",
      "   feature_name  importance\n",
      "7        cont_7    0.290323\n",
      "18       disc_3    0.158698\n",
      "3        cont_3    0.121800\n",
      "9        cont_9    0.082002\n",
      "0        cont_0    0.079184\n",
      "13      cont_13    0.049370\n",
      "16       disc_1    0.047804\n",
      "1        cont_1    0.038454\n",
      "11      cont_11    0.037351\n",
      "8        cont_8    0.016305\n",
      "Predictions saved to results/classification/predictions_low_Simple_RandomForest.csv\n"
     ]
    }
   ],
   "source": [
    "# Random Forest performance\n",
    "rf_low_results = analyze_model_performance(\n",
    "    \"RandomForest\", best_rf_low, X_train_low, y_train_low, X_test_low, y_test_low,\n",
    "    features, \"low\", \"Simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4432e58",
   "metadata": {},
   "source": [
    "# High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2eaed42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "Best parameters: {'bootstrap': True, 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 60, 'min_samples_split': 250, 'n_estimators': 150, 'oob_score': True}\n",
      "Best cross-validation Accuracy: 0.7600\n"
     ]
    }
   ],
   "source": [
    "# Random Forest - high data\n",
    "param_grid_rf_high = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [1, 2],\n",
    "    'min_samples_split': [150, 200, 250],\n",
    "    'min_samples_leaf': [60, 70, 80],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True],                         \n",
    "    'oob_score': [True]   \n",
    "}\n",
    "\n",
    "# train Random Forest \n",
    "rf_grid_high = train_random_forest_model(X_train_high, y_train_high, param_grid_rf_high, cv=10)\n",
    "best_rf_high = rf_grid_high.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d4e07257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of Simple imputed high RandomForest:\n",
      "Accuracy: 0.7743, F1-Score: 0.7927\n",
      "\n",
      "Test performance of Simple imputed high RandomForest:\n",
      "Accuracy: 0.7000, F1-Score: 0.7273\n",
      "\n",
      "Feature Importance for High Missing Data RandomForest:\n",
      "   feature_name  importance\n",
      "7        cont_7    0.213331\n",
      "9        cont_9    0.132970\n",
      "18       disc_3    0.124307\n",
      "11      cont_11    0.106349\n",
      "3        cont_3    0.073656\n",
      "0        cont_0    0.070218\n",
      "13      cont_13    0.063492\n",
      "16       disc_1    0.058489\n",
      "8        cont_8    0.027258\n",
      "6        cont_6    0.023280\n",
      "Predictions saved to results/classification/predictions_high_Simple_RandomForest.csv\n"
     ]
    }
   ],
   "source": [
    "# Random Forest performance\n",
    "rf_high_results = analyze_model_performance(\n",
    "    \"RandomForest\", best_rf_high, X_train_high, y_train_high, X_test_high, y_test_high,\n",
    "    features, \"high\", \"Simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342de61f",
   "metadata": {},
   "source": [
    "# 4.3 Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c660be",
   "metadata": {},
   "source": [
    "# Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5e67b365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "Best parameters: {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate_init': 0.001, 'max_iter': 2000}\n",
      "Best cross-validation Accuracy: 0.8914\n"
     ]
    }
   ],
   "source": [
    "# Neural Network - low data\n",
    "param_grid_nn_low = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],  \n",
    "    'activation': ['relu', 'tanh', 'logistic'],                               \n",
    "    'alpha': [0.0001, 0.001, 0.01],                             \n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],                        \n",
    "    'max_iter': [2000, 3000]                                                \n",
    "}\n",
    "\n",
    "# train Neural Network \n",
    "nn_grid_low = train_neural_network_model(X_train_low, y_train_low, param_grid_nn_low, cv=5)\n",
    "best_nn_low = nn_grid_low.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "49c268f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of Simple imputed low NeuralNetwork:\n",
      "Accuracy: 0.9157, F1-Score: 0.9184\n",
      "\n",
      "Test performance of Simple imputed low NeuralNetwork:\n",
      "Accuracy: 0.9433, F1-Score: 0.9450\n",
      "\n",
      "Feature Importance for Low Missing Data NeuralNetwork:\n",
      "   feature_name  importance\n",
      "18       disc_3    0.159667\n",
      "7        cont_7    0.139333\n",
      "16       disc_1    0.121000\n",
      "3        cont_3    0.106333\n",
      "0        cont_0    0.099333\n",
      "20    cat_0_Yes    0.046000\n",
      "9        cont_9    0.043667\n",
      "22    cat_2_Yes    0.041667\n",
      "11      cont_11    0.039000\n",
      "13      cont_13    0.033000\n",
      "Predictions saved to results/classification/predictions_low_Simple_NeuralNetwork.csv\n"
     ]
    }
   ],
   "source": [
    "#  Neural Network performance\n",
    "nn_low_results = analyze_model_performance(\n",
    "    \"NeuralNetwork\", best_nn_low, X_train_low, y_train_low, X_test_low, y_test_low,\n",
    "    features, \"low\", \"Simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cba80b",
   "metadata": {},
   "source": [
    "# High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8eb5bc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "Best parameters: {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001, 'max_iter': 2000}\n",
      "Best cross-validation Accuracy: 0.8186\n"
     ]
    }
   ],
   "source": [
    "# Neural Network - high \n",
    "param_grid_nn_high = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],  \n",
    "    'activation': ['relu', 'tanh', 'logistic'],                  \n",
    "    'alpha': [0.0001, 0.001, 0.01],                             \n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],                   \n",
    "    'max_iter': [2000, 3000]                                     \n",
    "}\n",
    "\n",
    "# train Neural Network \n",
    "nn_grid_high = train_neural_network_model(X_train_high, y_train_high, param_grid_nn_high, cv=5)\n",
    "best_nn_high = nn_grid_high.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8f6abb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training performance of Simple imputed high NeuralNetwork:\n",
      "Accuracy: 0.8400, F1-Score: 0.8427\n",
      "\n",
      "Test performance of Simple imputed high NeuralNetwork:\n",
      "Accuracy: 0.8667, F1-Score: 0.8750\n",
      "\n",
      "Feature Importance for High Missing Data NeuralNetwork:\n",
      "   feature_name  importance\n",
      "18       disc_3    0.136333\n",
      "7        cont_7    0.131333\n",
      "16       disc_1    0.059667\n",
      "3        cont_3    0.056000\n",
      "0        cont_0    0.045667\n",
      "13      cont_13    0.040333\n",
      "9        cont_9    0.037667\n",
      "22    cat_2_Yes    0.024000\n",
      "20    cat_0_Yes    0.021667\n",
      "11      cont_11    0.014667\n",
      "Predictions saved to results/classification/predictions_high_Simple_NeuralNetwork.csv\n"
     ]
    }
   ],
   "source": [
    "# Neural Network performance\n",
    "nn_high_results = analyze_model_performance(\n",
    "    \"NeuralNetwork\", best_nn_high, X_train_high, y_train_high, X_test_high, y_test_high,\n",
    "    features, \"high\", \"Simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9966ca",
   "metadata": {},
   "source": [
    "# Simple summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9bf72c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SIMPLE IMPUTATION RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Simple Imputation Classification performance summary:\n",
      "            Dataset     Classifier  Train_Accuracy  Train_F1  Test_Accuracy  Test_F1\n",
      " Simple_Low_Missing            SVM          0.9071    0.9096         0.9500   0.9515\n",
      "Simple_High_Missing            SVM          0.8386    0.8388         0.8800   0.8882\n",
      " Simple_Low_Missing  Random_Forest          0.8386    0.8487         0.7800   0.7885\n",
      "Simple_High_Missing  Random_Forest          0.7743    0.7927         0.7000   0.7273\n",
      " Simple_Low_Missing Neural_Network          0.9157    0.9184         0.9433   0.9450\n",
      "Simple_High_Missing Neural_Network          0.8400    0.8427         0.8667   0.8750\n",
      "   Complete_Dataset            SVM          0.9843    0.9846         0.9767   0.9773\n",
      "   Complete_Dataset  Random_Forest          0.8686    0.8757         0.7900   0.8037\n",
      "   Complete_Dataset Neural_Network          1.0000    1.0000         0.9733   0.9742\n",
      "================================================================================\n",
      "Test Accuracy by Dataset and Classifier\n",
      "================================================================================\n",
      "Classifier           Neural_Network  Random_Forest     SVM\n",
      "Dataset                                                   \n",
      "Complete_Dataset             0.9733           0.79  0.9767\n",
      "Simple_High_Missing          0.8667           0.70  0.8800\n",
      "Simple_Low_Missing           0.9433           0.78  0.9500\n",
      "================================================================================\n",
      "Test F1 Score by Dataset and Classifier\n",
      "================================================================================\n",
      "Classifier           Neural_Network  Random_Forest     SVM\n",
      "Dataset                                                   \n",
      "Complete_Dataset             0.9742         0.8037  0.9773\n",
      "Simple_High_Missing          0.8750         0.7273  0.8882\n",
      "Simple_Low_Missing           0.9450         0.7885  0.9515\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SIMPLE IMPUTATION RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "simple_results_summary = [\n",
    "    # SVM \n",
    "    {\n",
    "        'Dataset': 'Simple_Low_Missing',\n",
    "        'Classifier': 'SVM',\n",
    "        'Train_Accuracy': svm_low_results['results']['train_accuracy'],\n",
    "        'Train_F1': svm_low_results['results']['train_f1'],\n",
    "        'Test_Accuracy': svm_low_results['results']['test_accuracy'],\n",
    "        'Test_F1': svm_low_results['results']['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Simple_High_Missing',\n",
    "        'Classifier': 'SVM',\n",
    "        'Train_Accuracy': svm_high_results['results']['train_accuracy'],\n",
    "        'Train_F1': svm_high_results['results']['train_f1'],\n",
    "        'Test_Accuracy': svm_high_results['results']['test_accuracy'],\n",
    "        'Test_F1': svm_high_results['results']['test_f1']\n",
    "    },\n",
    "    # Random Forest \n",
    "    {\n",
    "        'Dataset': 'Simple_Low_Missing',\n",
    "        'Classifier': 'Random_Forest',\n",
    "        'Train_Accuracy': rf_low_results['results']['train_accuracy'],\n",
    "        'Train_F1': rf_low_results['results']['train_f1'],\n",
    "        'Test_Accuracy': rf_low_results['results']['test_accuracy'],\n",
    "        'Test_F1': rf_low_results['results']['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Simple_High_Missing',\n",
    "        'Classifier': 'Random_Forest',\n",
    "        'Train_Accuracy': rf_high_results['results']['train_accuracy'],\n",
    "        'Train_F1': rf_high_results['results']['train_f1'],\n",
    "        'Test_Accuracy': rf_high_results['results']['test_accuracy'],\n",
    "        'Test_F1': rf_high_results['results']['test_f1']\n",
    "    },\n",
    "    # Neural Network \n",
    "    {\n",
    "        'Dataset': 'Simple_Low_Missing',\n",
    "        'Classifier': 'Neural_Network',\n",
    "        'Train_Accuracy': nn_low_results['results']['train_accuracy'],\n",
    "        'Train_F1': nn_low_results['results']['train_f1'],\n",
    "        'Test_Accuracy': nn_low_results['results']['test_accuracy'],\n",
    "        'Test_F1': nn_low_results['results']['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Simple_High_Missing',\n",
    "        'Classifier': 'Neural_Network',\n",
    "        'Train_Accuracy': nn_high_results['results']['train_accuracy'],\n",
    "        'Train_F1': nn_high_results['results']['train_f1'],\n",
    "        'Test_Accuracy': nn_high_results['results']['test_accuracy'],\n",
    "        'Test_F1': nn_high_results['results']['test_f1']\n",
    "    },\n",
    "    # Complete dataset \n",
    "    {\n",
    "        'Dataset': 'Complete_Dataset',\n",
    "        'Classifier': 'SVM',\n",
    "        'Train_Accuracy': svm_complete_results['results']['train_accuracy'],\n",
    "        'Train_F1': svm_complete_results['results']['train_f1'],\n",
    "        'Test_Accuracy': svm_complete_results['results']['test_accuracy'],\n",
    "        'Test_F1': svm_complete_results['results']['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Complete_Dataset',\n",
    "        'Classifier': 'Random_Forest',\n",
    "        'Train_Accuracy': rf_complete_results['results']['train_accuracy'],\n",
    "        'Train_F1': rf_complete_results['results']['train_f1'],\n",
    "        'Test_Accuracy': rf_complete_results['results']['test_accuracy'],\n",
    "        'Test_F1': rf_complete_results['results']['test_f1']\n",
    "    },\n",
    "    {\n",
    "        'Dataset': 'Complete_Dataset',\n",
    "        'Classifier': 'Neural_Network',\n",
    "        'Train_Accuracy': nn_complete_results['results']['train_accuracy'],\n",
    "        'Train_F1': nn_complete_results['results']['train_f1'],\n",
    "        'Test_Accuracy': nn_complete_results['results']['test_accuracy'],\n",
    "        'Test_F1': nn_complete_results['results']['test_f1']\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "simple_results_df = pd.DataFrame(simple_results_summary)\n",
    "simple_results_df = simple_results_df.round(4)\n",
    "\n",
    "print(\"\\nSimple Imputation Classification performance summary:\")\n",
    "print(simple_results_df.to_string(index=False))\n",
    "\n",
    "# pivot tables\n",
    "print(\"=\" * 80)\n",
    "print(\"Test Accuracy by Dataset and Classifier\")\n",
    "print(\"=\" * 80)\n",
    "pivot_accuracy = simple_results_df.pivot(index='Dataset', columns='Classifier', values='Test_Accuracy')\n",
    "print(pivot_accuracy.round(4))\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Test F1 Score by Dataset and Classifier\")\n",
    "print(\"=\" * 80)\n",
    "pivot_f1 = simple_results_df.pivot(index='Dataset', columns='Classifier', values='Test_F1')\n",
    "print(pivot_f1.round(4))\n",
    "\n",
    "# save results\n",
    "simple_results_df.to_csv('results/classification/simple_classification_results.csv', index=False)\n",
    "pivot_accuracy.to_csv('results/classification/simple_accuracy_pivot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32590e4a",
   "metadata": {},
   "source": [
    "# Master comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee73a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MASTER COMPARISON - ALL IMPUTATION METHODS\n",
      "================================================================================\n",
      "\n",
      "TEST RESULTS - LOW MISSING DATA\n",
      "--------------------------------------------------\n",
      "            Test_Accuracy                              Test_F1                \\\n",
      "Classifier Neural_Network Random_Forest     SVM Neural_Network Random_Forest   \n",
      "Imputation                                                                     \n",
      "KNN                0.9300        0.7600  0.9433         0.9325        0.7616   \n",
      "MICE               0.9500        0.8033  0.9500         0.9511        0.8162   \n",
      "None               0.9733        0.7900  0.9767         0.9742        0.8037   \n",
      "Simple             0.9433        0.7800  0.9500         0.9450        0.7885   \n",
      "\n",
      "                    \n",
      "Classifier     SVM  \n",
      "Imputation          \n",
      "KNN         0.9453  \n",
      "MICE        0.9518  \n",
      "None        0.9773  \n",
      "Simple      0.9515  \n",
      "\n",
      "TEST RESULTS - HIGH MISSING DATA\n",
      "--------------------------------------------------\n",
      "            Test_Accuracy                              Test_F1                \\\n",
      "Classifier Neural_Network Random_Forest     SVM Neural_Network Random_Forest   \n",
      "Imputation                                                                     \n",
      "KNN                0.8467        0.6667  0.8600         0.8623        0.6988   \n",
      "MICE               0.8233        0.8033  0.8200         0.8307        0.8127   \n",
      "None               0.9733        0.7900  0.9767         0.9742        0.8037   \n",
      "Simple             0.8667        0.7000  0.8800         0.8750        0.7273   \n",
      "\n",
      "                    \n",
      "Classifier     SVM  \n",
      "Imputation          \n",
      "KNN         0.8720  \n",
      "MICE        0.8269  \n",
      "None        0.9773  \n",
      "Simple      0.8882  \n"
     ]
    }
   ],
   "source": [
    "# master comparison for all imputation methods\n",
    "print(\"=\" * 80)\n",
    "print(\"MASTER COMPARISON - ALL IMPUTATION METHODS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_results = pd.concat([\n",
    "    knn_results_df, \n",
    "    mice_results_df, \n",
    "    simple_results_df\n",
    "])\n",
    "\n",
    "\n",
    "all_results = all_results.drop_duplicates()\n",
    "\n",
    "\n",
    "all_results['Imputation'] = all_results['Dataset'].apply(\n",
    "    lambda x: 'None' if 'Complete' in x \n",
    "              else 'KNN' if 'KNN' in x \n",
    "              else 'MICE' if 'MICE' in x \n",
    "              else 'Simple' if 'Simple' in x \n",
    "              else 'Unknown'\n",
    ")\n",
    "all_results['Missing_Level'] = all_results['Dataset'].apply(\n",
    "    lambda x: 'None' if 'Complete' in x \n",
    "              else 'Low' if 'Low' in x \n",
    "              else 'High' if 'High' in x \n",
    "              else 'Unknown'\n",
    ")\n",
    "\n",
    "# test results low\n",
    "print(\"\\nTEST RESULTS - LOW MISSING DATA\")\n",
    "print(\"-\" * 50)\n",
    "low_results = all_results[\n",
    "    (all_results['Missing_Level'] == 'Low') | \n",
    "    (all_results['Missing_Level'] == 'None')\n",
    "]\n",
    "\n",
    "low_summary = low_results.pivot_table(\n",
    "    index='Imputation',\n",
    "    columns='Classifier',\n",
    "    values=['Test_Accuracy', 'Test_F1']\n",
    ").round(4)\n",
    "\n",
    "print(low_summary)\n",
    "low_summary.to_csv('results/classification/low_missing_results.csv')\n",
    "\n",
    "# 2. test high\n",
    "print(\"\\nTEST RESULTS - HIGH MISSING DATA\")\n",
    "print(\"-\" * 50)\n",
    "high_results = all_results[\n",
    "    (all_results['Missing_Level'] == 'High') | \n",
    "    (all_results['Missing_Level'] == 'None')\n",
    "]\n",
    "\n",
    "high_summary = high_results.pivot_table(\n",
    "    index='Imputation',\n",
    "    columns='Classifier',\n",
    "    values=['Test_Accuracy', 'Test_F1']\n",
    ").round(4)\n",
    "\n",
    "print(high_summary)\n",
    "high_summary.to_csv('results/classification/high_missing_results.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
